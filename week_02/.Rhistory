sd(y)
mean(y)
new1 <- data.frame(x = 40000)
new2 <- data.frame(x = 80000)
fourth_sample <- posterior_predict(model, new1)
eighth_sample <- posterior_predict(model, new2)
vector_of_differences <- eighth_sample-fourth_sample
vector_of_differences
vector_of_differences <- data.frame(vector_of_differences)
#Need to find 90% interval of this this
box_plot <- ggplot(vector_of_differences, aes(x = X1))+
geom_boxplot()
box_plot
quantile(vector_of_differences$X1, probs = 0.05)
quantile(vector_of_differences$X1, probs = 0.95)
#9.3
hibbs <- read.table('https://raw.githubusercontent.com/avehtari/ROS-Examples/example-student/ElectionsEconomy/data/hibbs.dat', header=TRUE)
hibbs_model <- stan_glm(inc.party.vote ~ growth, data=hibbs)
data_again <- data.frame(growth = 2.00)
point_predict_2 <- predict(hibbs_model, newdata = data_again)
point_predict_2
point_predict_2
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/Methods 2")
library(tidyverse)
library(rstanarm)
library(bayesplot)
set.seed(0)
library(RColorBrewer)
# display.brewer.pal(n = 8, name = 'Set1')
colours <- brewer.pal(n = 8, name = 'Set1')
#Setup
knitr::opts_chunk$set(echo = TRUE)
#The following is to be able to knit to a pdf:
library(tinytex)
tinytex::install_tinytex()
pacman::p_load('formatR')
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
setwd("~/Desktop/Methods 2")
library(tidyverse)
library(rstanarm)
library(bayesplot)
set.seed(0)
#Loading the data
pollution <- read_csv("pollution.csv")
head(pollution)
mortality_plot <- ggplot(pollution, aes(x = nox, y = mort))+
geom_point()+
labs(x = "Level of nitric oxides",
y = "Mortality Rate", title = "Scatterplot of mortality rate versus level of nitric oxides")
mortality_plot
fit1 <- stan_glm(mort ~ nox, data = pollution, refresh = 0)
fit1
#calculating the residuals by subtracting predicted values from observed values
pollution_2 <- pollution
pollution_2$predicted <- predict(fit1)
pollution_2$residuals <- (pollution_2$mort)-(pollution_2$predicted)
# Plotting the residuals and the predicted values
residualplot_fit1 <- ggplot(pollution_2, aes(x = nox, y = mort)) +
geom_abline(intercept = fit1$coefficients[[1]],
slope = fit1$coefficients[[2]],
size = 0.5)+
geom_segment(aes(xend = nox, yend = predicted), alpha = .2)+
geom_point() +
geom_point(aes(y = predicted), shape = 1)+
labs(x = "Level of nitric oxides",
y = "Mortality Rate", title = "Residual plot")
residualplot_fit1
(fit2 <- stan_glm(log(mort) ~ log(nox), data = pollution, refresh = 0)) %>% print(digits = 2)
fit2_plot <- ggplot(pollution, aes(x = log(nox), y = log(mort)))+
geom_point()+
geom_abline(intercept = fit2$coefficients[[1]],
slope = fit2$coefficients[[2]],
size = 1.1)+
labs(x = "Log-transformed levels of nitric oxides",
y = "Log-transformed mortality rate", title = "Scatterplot of log-transformed values")
fit2_plot
pollution_3 <- pollution
pollution_3$predicted <- predict(fit2)
pollution_3$residuals <- (log(pollution_3$mort))-(pollution_3$predicted)
residualplot_fit2 <- ggplot(pollution_3, aes(x = log(nox), y = log(mort))) +
geom_abline(intercept = fit2$coefficients[[1]],
slope = fit2$coefficients[[2]],
size = 0.5)+
geom_segment(aes(xend = log(nox), yend = predicted), alpha = .2)+
geom_point() +
geom_point(aes(y = predicted), shape = 1)+
labs(x = "Log-transformed level of nitric oxides",
y = "Log-transformed mortality Rate", title = "Residual plot using log-transformed values")
residualplot_fit2
print(fit2, digits = 2)
# Plotting the sulfur dioxide and hydrocarbon variables
so2_plot <- ggplot(pollution, aes(x = so2, y = mort))+
geom_point()+
labs(x = "Level of sulfur dioxide",
y = "Mortality Rate", title = "Scatterplot of levels of sulfur dioxide versus mortality rate")
so2_plot
hc_plot <- ggplot(pollution, aes(x = hc, y = mort))+
geom_point()+
labs(x = "Level of hydrocarbons",
y = "Mortality Rate", title = "Scatterplot of levels of hydrocarbons versus mortality rate")
hc_plot
(fit3 <- stan_glm(log(mort) ~ log(nox) + log(hc) + log(so2), data = pollution, refresh = 0)) %>% print(digits = 2)
pacman::p_load("caTools")
# The sample.split() function divides our dataset in half
samplesplit <- sample.split(seq_len(nrow(pollution)), 0.5)
# We then define a training and testing dataset
train <- pollution[samplesplit, ]
test <-  pollution[!samplesplit, ]
# Fitting a new model on the train dataset, which only contains half of the observations of the original dataframe
(cv_model <- stan_glm(log(mort) ~ log(nox) + log(hc) + log(so2), data = train, refresh = 0)) %>% print(digits = 2)
# Predicting values using our new model on the other half of the dataset
predicted_values <- predict(cv_model, newdata = test)
# combining the "test" data and the predicted values in a new dataframe
df <- data.frame(test, predicted_values)
# calculating the residuals
df$residuals <- log(df$mort) - df$predicted_values
# plotting the observed values vs the predicted values
predicted_plot <- ggplot(df, aes(x = log(mort), y = predicted_values)) +
geom_point()+
geom_point(aes(x = log(mort), y = predicted_values), shape = 1)+
labs(x = "Observed mortality values",
y = "Predicted mortality values", title = "Observed values versus predicted values")
predicted_plot
predicted_plot <- ggplot(df, aes(x = log(mort), y = predicted_values)) +
geom_point()+
geom_point(aes(x = log(mort), y = predicted_values), shape = 1)+
labs(x = "Observed mortality values",
y = "Predicted mortality values", title = "Observed values versus predicted values")+
geom_abline(intercept = 0,
1,
size = 0.5)
predicted_plot
predicted_plot <- ggplot(df, aes(x = log(mort), y = predicted_values)) +
geom_point()+
geom_point(aes(x = log(mort), y = predicted_values), shape = 1)+
labs(x = "Observed mortality values",
y = "Predicted mortality values", title = "Observed values versus predicted values")+
geom_abline(intercept = 0,
1,
size = 0.5)+
scale_x_continuous(limits = c(0, 8))+
scale_y_continuous(limits = c(0, 8))
predicted_plot
predicted_plot <- ggplot(df, aes(x = log(mort), y = predicted_values)) +
geom_point()+
geom_point(aes(x = log(mort), y = predicted_values), shape = 1)+
labs(x = "Observed mortality values",
y = "Predicted mortality values", title = "Observed values versus predicted values")+
geom_abline(intercept = 0,
1,
size = 0.5)+
scale_x_continuous(limits = c(5, 8))+
scale_y_continuous(limits = c(5, 8))
predicted_plot
predicted_plot <- ggplot(df, aes(x = log(mort), y = predicted_values)) +
geom_point()+
geom_point(aes(x = log(mort), y = predicted_values), shape = 1)+
labs(x = "Observed mortality values",
y = "Predicted mortality values", title = "Observed values versus predicted values")+
geom_abline(intercept = 0,
1,
size = 0.5)+
scale_x_continuous(limits = c(7, 8))+
scale_y_continuous(limits = c(7, 8))
predicted_plot
predicted_plot <- ggplot(df, aes(x = log(mort), y = predicted_values)) +
geom_point()+
geom_point(aes(x = log(mort), y = predicted_values), shape = 1)+
labs(x = "Observed mortality values",
y = "Predicted mortality values", title = "Observed values versus predicted values")+
geom_abline(intercept = 0,
1,
size = 0.5)+
scale_x_continuous(limits = c(6, 8))+
scale_y_continuous(limits = c(6, 8))
predicted_plot
predicted_plot <- ggplot(df, aes(x = log(mort), y = predicted_values)) +
geom_point()+
geom_point(aes(x = log(mort), y = predicted_values), shape = 1)+
labs(x = "Observed mortality values",
y = "Predicted mortality values", title = "Observed values versus predicted values")+
geom_abline(intercept = 0,
1,
size = 0.5)+
scale_x_continuous(limits = c(6.5, 7))+
scale_y_continuous(limits = c(6.5, 7))
predicted_plot
predicted_plot <- ggplot(df, aes(x = log(mort), y = predicted_values)) +
geom_point()+
geom_point(aes(x = log(mort), y = predicted_values), shape = 1)+
labs(x = "Observed mortality values",
y = "Predicted mortality values", title = "Observed values versus predicted values")+
geom_abline(intercept = 0,
1,
size = 0.5)+
scale_x_continuous(limits = c(6.6, 7))+
scale_y_continuous(limits = c(6.6, 7))
predicted_plot
predicted_plot <- ggplot(df, aes(x = log(mort), y = predicted_values)) +
geom_point()+
geom_point(aes(x = log(mort), y = predicted_values), shape = 1)+
labs(x = "Observed mortality values",
y = "Predicted mortality values", title = "Observed values versus predicted values")+
geom_abline(intercept = 0,
1,
size = 0.5)+
scale_x_continuous(limits = c(6.6, 7))+
scale_y_continuous(limits = c(6.6, 7))+
geom_segment(aes(xend = log(mort), yend = predicted_values), alpha = .2)
predicted_plot
predicted_plot <- ggplot(df, aes(x = log(mort), y = predicted_values)) +
geom_segment(aes(xend = log(mort), yend = predicted_values), alpha = .2)+
geom_point()+
geom_point(aes(x = log(mort), y = predicted_values), shape = 1)+
labs(x = "Observed mortality values",
y = "Predicted mortality values", title = "Observed values versus predicted values")+
geom_abline(intercept = 0,
1,
size = 0.5)+
scale_x_continuous(limits = c(6.6, 7))+
scale_y_continuous(limits = c(6.6, 7))+
geom_segment(aes(xend = log(mort), yend = predicted_values), alpha = .2)
predicted_plot
predicted_plot <- ggplot(df, aes(x = log(mort), y = predicted_values)) +
geom_segment(aes(xend = log(mort), yend = predicted_values), alpha = .2)+
geom_point()+
geom_point(aes(x = log(mort), y = predicted_values), shape = 1)+
labs(x = "Observed mortality values",
y = "Predicted mortality values", title = "Observed values versus predicted values")+
geom_abline(intercept = 0,
1,
size = 0.5)+
scale_x_continuous(limits = c(6.6, 7))+
scale_y_continuous(limits = c(6.6, 7))+
geom_segment(aes(xend = log(mort), yend = geom_abline(intercept = 0, 1, size = 0.5)), alpha = .2)
predicted_plot
predicted_plot <- ggplot(df, aes(x = log(mort), y = predicted_values)) +
geom_segment(aes(xend = log(mort), yend = predicted_values), alpha = .2)+
geom_point()+
geom_point(aes(x = log(mort), y = predicted_values), shape = 1)+
labs(x = "Observed mortality values",
y = "Predicted mortality values", title = "Observed values versus predicted values")+
geom_abline(intercept = 0,
1,
size = 0.5)+
scale_x_continuous(limits = c(6.6, 7))+
scale_y_continuous(limits = c(6.6, 7))+
geom_segment(aes(xend = log(mort), yend = predicted_values), alpha = .2)+
predicted_plot
predicted_plot <- ggplot(df, aes(x = log(mort), y = predicted_values)) +
geom_segment(aes(xend = log(mort), yend = predicted_values), alpha = .2)+
geom_point()+
geom_point(aes(x = log(mort), y = predicted_values), shape = 1)+
labs(x = "Observed mortality values",
y = "Predicted mortality values", title = "Observed values versus predicted values")+
geom_abline(intercept = 0,
1,
size = 0.5)+
scale_x_continuous(limits = c(6.6, 7))+
scale_y_continuous(limits = c(6.6, 7))+
geom_segment(aes(xend = log(mort), yend = predicted_values), alpha = .2)
predicted_plot
intercept <- log(10)-(2*log(50))
intercept
intercept
exp(intercept)
intercept
sigma <- log(1.1)/2
sigma
sd <- 0.2
rsquared <- 1-((sigma^2)/(sd^2))
rsquared
hej <- (1.1)/2
hej <- (1.1)/2
sigma <- log(hej)
sigma
sigma <- log(1.1)/2
sigma
log(1.1)
sigma <- log(1.1)/2
sigma
sd <- 0.2
rsquared <- 1-((sigma^2)/(sd^2))
rsquared
#Reading the beauty csv file
beauty <- read_csv("beauty.csv")
View(beauty)
(beauty1 <- stan_glm(eval ~ beauty, data = beauty, refresh = 0)) %>% print(digits = 2)
(beauty2 <- stan_glm(eval ~ beauty*female, data = beauty, refresh = 0)) %>% print(digits = 2)
(beauty3 <- stan_glm(eval ~ beauty*female + beauty*age, data = beauty, refresh = 0)) %>% print(digits = 3)
(beauty4 <- stan_glm(eval ~ beauty*female + minority, data = beauty, refresh = 0)) %>% print(digits = 3)
(beauty5 <- stan_glm(eval ~ beauty*female + minority*female + beauty*age, data = beauty, refresh = 0)) %>% print(digits = 3)
(beauty4 <- stan_glm(eval ~ beauty*female + minority, data = beauty, refresh = 0)) %>% print(digits = 3)
(beauty5 <- stan_glm(eval ~ beauty*female + minority*female + beauty*age, data = beauty, refresh = 0)) %>% print(digits = 3)
minority <- filter(beauty, minority == 1 & female == 1)
loo1 <- loo(beauty1)
loo2 <- loo(beauty2)
loo3 <- loo(beauty3)
loo4 <- loo(beauty4)
loo5 <- loo(beauty5)
loo_compare(loo1, loo2, loo3, loo4, loo5)
(beauty5 <- stan_glm(eval ~ beauty*female + beauty*minority + beauty*age, data = beauty, refresh = 0)) %>% print(digits = 3)
(beauty5 <- stan_glm(eval ~ beauty*female + beauty*minority + beauty*age, data = beauty, refresh = 0)) %>% print(digits = 3)
loo1 <- loo(beauty1)
loo2 <- loo(beauty2)
loo3 <- loo(beauty3)
loo4 <- loo(beauty4)
loo5 <- loo(beauty5)
loo_compare(loo1, loo2, loo3, loo4, loo5)
R2_beauty3<-bayes_R2(beauty3)
R2_beauty5<-bayes_R2(beauty5)
round(median(R2_beauty3),3)
round(median(R2_beauty5),3)
pp_check(beauty3)
pp_check(beauty5)
R2_beauty2<-bayes_R2(beauty2)
round(median(R2_beauty2),3)
round(median(R2_beauty2),3)
round(median(R2_beauty3),3)
round(median(R2_beauty5),3)
pp_check(beauty2)
pp_check(beauty3)
pp_check(beauty5)
print(beauty3, digits = 3)
(beauty2 <- stan_glm(eval ~ female*beauty, data = beauty, refresh = 0)) %>% print(digits = 2)
(beauty3 <- stan_glm(eval ~ female*beauty + age*beauty, data = beauty, refresh = 0)) %>% print(digits = 3)
(beauty4 <- stan_glm(eval ~ female*beauty + minority, data = beauty, refresh = 0)) %>% print(digits = 3)
(beauty5 <- stan_glm(eval ~ female*beauty + minority*beauty + age*beauty, data = beauty, refresh = 0)) %>% print(digits = 3)
loo1 <- loo(beauty1)
loo2 <- loo(beauty2)
loo3 <- loo(beauty3)
loo4 <- loo(beauty4)
loo5 <- loo(beauty5)
loo_compare(loo1, loo2, loo3, loo4, loo5)
R2_beauty2<-bayes_R2(beauty2)
R2_beauty3<-bayes_R2(beauty3)
R2_beauty5<-bayes_R2(beauty5)
round(median(R2_beauty2),3)
round(median(R2_beauty3),3)
round(median(R2_beauty5),3)
pp_check(beauty2)
pp_check(beauty3)
pp_check(beauty5)
print(beauty3, digits = 3)
(beauty5 <- stan_glm(eval ~ female*beauty + minority*beauty + age*beauty, data = beauty, refresh = 0)) %>% print(digits = 3)
loo1 <- loo(beauty1)
loo2 <- loo(beauty2)
loo3 <- loo(beauty3)
loo4 <- loo(beauty4)
loo5 <- loo(beauty5)
loo_compare(loo1, loo2, loo3, loo4, loo5)
print(beauty3, digits = 3)
(beauty3 <- stan_glm(eval ~ female*beauty + age*beauty, data = beauty, refresh = 0)) %>% print(digits = 3)
#an alternative spelling of pacman::p_load() is to call library(pacman) followed by p_load
library(pacman);p_load(tidyverse, boot, lmerTest, caret, e1071)
#load data
load(file = "kikibobo.Rda")
#try to give a name and fail
df <- load(file = "kikibobo.Rda")
df #the output is just a character string 'kikibobo3'
#delete useless df variable from environment
rm(df)
better_bobo <- as_tibble(kikibobo3)
better_bobo <- subset(better_bobo, select = -c(X))
better_bobo$id <- as.factor(better_bobo$id)
better_bobo$id <- as.numeric(better_bobo$id)
better_bobo$id <- as.factor(better_bobo$id)
head(better_bobo)
class(better_bobo$shape)
levels(better_bobo$shape)
#make a GLM model for shape
m <- glm(shape ~ consonant,
data = better_bobo, #  (use your data name here)
family = binomial)
summary(m)
#see levels of outcome variable: 0 and 1. Model estimates log odds for level 1
levels(better_bobo$shape)
#see summary again to see log odds
summary(m)
#log odds into probability for estimate of intercept (the probability of jagged shape given letter B)
boot::inv.logit(-1.5882)
#log odds into probability for estimate of going from letter B to letter K
boot::inv.logit(-1.5882 + 2.5576)
#see summary again to see log odds
summary(m2)
setwd("~/Desktop/github_methods_3/week_02")
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/github_methods_3/week_02")
politeness <- read.csv('politeness.csv') ## read in data
View(politeness)
library(lmer)
library('lmer')
install.packages('lmer')
library(lmer)
library('lmer')
library('lme4')
max(politeness$scenario)
aud[sapply(aud, is.character)] <- lapply(aud[sapply(aud, is.character)],
as.factor)
politeness[sapply(politeness, is.character)] <- lapply(politeness[sapply(politeness, is.character)],
as.factor)
politeness$scenario <- as.factor(politeness$scenario)
f1 <- politeness %>%
filter(subject == "F1")
library('lme4', 'tidyverse')
library('lme4', 'tidyverse', 'lme4')
f1 <- politeness %>%
filter(subject == "F1")
pacman::p_load("tidyverse")
f1 <- politeness %>%
filter(subject == "F1")
View(f1)
politeness <- read.csv('politeness.csv') ## read in data
#Making all the variables that are characters to factors
politeness[sapply(politeness, is.character)] <- lapply(politeness[sapply(politeness, is.character)],
as.factor)
f1 <- politeness %>%
filter(subject == "F1")
politeness$scenario <- as.factor(politeness$scenario)
politeness <- read.csv('politeness.csv') ## read in data
#Making all the variables that are characters to factors
politeness[sapply(politeness, is.character)] <- lapply(politeness[sapply(politeness, is.character)],
as.factor)
f1 <- politeness %>%
filter(subject == "F1")
f1model_1 <- lm(f0mn ~ scenario, data = f1)
summary(f1model_1)
#making scenario a factor and fitting a new model
politeness$scenario <- as.factor(politeness$scenario)
f1model_2 <- lm(f0mn ~ scenario, data = f1)
summary(f1model_2)
#making scenario a factor and fitting a new model
f1$scenario <- as.factor(f1$scenario)
f1model_2 <- lm(f0mn ~ scenario, data = f1)
summary(f1model_2)
model.matrix(f1model_1)
model.matrix(f1model_1)
model.matrix(f1model_2)
# Thus, I am making scenario as a factor
politeness$scenario <- as.factor(politeness$scenario)
ggplot(politeness, aes(x = scenario, y = f0mn, color = attitude))+
geom_point()+
facet_wrap(~Subject)+
theme_classic()
ggplot(politeness, aes(x = scenario, y = f0mn, color = attitude))+
geom_point()+
facet_wrap(~subject)+
theme_classic()
ggplot(politeness, aes(x = scenario, y = f0mn, color = attitude))+
geom_point()+
facet_wrap(~subject)+
theme_minimal()
ggplot(politeness, aes(x = scenario, y = f0mn, color = attitude))+
geom_point()+
facet_wrap(~subject)+
theme_minimal()+
ylab("Frequency in Hz")
pacman::p_load("tidyverse")
pacman::p_load("tidyverse")
gender_model <- lm(f0mn ~ gender, data = politeness)
summary(gender_model)
lmer_gender_model <- lmer(f0mn ~ gender + (1|scenario), data = politeness)
summary(lmer_gender_model)
lmer_gender_model_subject <- lmer(f0mn ~ gender + (1|subject), data = politeness)
summary(lmer_gender_model_subject)
lmer_gender_model_both <- lmer(f0mn ~ gender + (1|subject) + (1|scenario), data = politeness)
summary(lmer_gender_model_both)
models <- c(gender_model, lmer_gender_model, lmer_gender_model_subject, lmer_gender_model_both)
AIC(gender_model, lmer_gender_model, lmer_gender_model_subject, lmer_gender_model_both)
View(f1)
ssr_gender_model <- sum((politeness$f0mn - predict(politeness$f0mn))^2)
View(politeness)
gender_model_y <- politeness$f0mn
#gender_model_y <- politeness$f0mn
#gender_model_yhat <- predict(politeness$f0mn)
ssr_gender_model <- sqrt(sum((politeness$f0mn - predict(gender_model)^2))/(nrow(politeness)-2))
#gender_model_y <- politeness$f0mn
gender_model_yhat <- predict(gender_model)
politness_new <- na.omit(politeness)
politeness_new <- na.omit(politeness)
ssr_gender_model <- sqrt(sum((politeness_new$f0mn - predict(gender_model)^2))/(nrow(politeness_new)-2))
gender_model_y <- politeness_new$f0mn
gender_model_yhat <- predict(gender_model)
ssr_gender_model <- sqrt(sum((gender_model_y - gender_model_yhat)^2)/(nrow(politeness_new)-2))
ssr_lmer_gender_model <- sqrt(sum((gender_model_y - lmer_gender_model)^2)/(nrow(politeness_new)-2))
lmer_gender_model_yhat <- predict(lmer_gender_model)
ssr_lmer_gender_model <- sqrt(sum((gender_model_y - lmer_gender_model)^2)/(nrow(politeness_new)-2))
gender_model_y <- politeness_new$f0mn
lmer_gender_model_yhat <- predict(lmer_gender_model)
ssr_lmer_gender_model <- sqrt(sum((gender_model_y - lmer_gender_model)^2)/(nrow(politeness_new)-2))
lmer_gender_model_yhat <- predict(lmer_gender_model)
ssr_lmer_gender_model_subject <- sqrt(sum((gender_model_y - lmer_gender_model_subject)^2)/(nrow(politeness_new)-2))
average_df <- 0
average_df <- data.frame(0)
View(average_df)
average_df <- 0
average_df <- data.frame()
View(average_df)
trydf <- politeness_new %>%
group_by(subject) %>%
summarise(f0mn = mean(f0mn))
View(trydf)
average_df <- politeness_new %>%
group_by(subject) %>%
summarise(f0mn = mean(f0mn))
View(average_df)
average_df$gender <- ifelse(grepl('F$', average_df$subject), 'F', 'M')
average_df$gender <- ifelse(grepl('F*', average_df$subject), 'F', 'M')
average_df$gender <- ifelse(grepl('F', average_df$subject), 'F', 'M')
single_level_model <- lm(f0mn ~ gender, data = average_df)
summary(single_level_model)
